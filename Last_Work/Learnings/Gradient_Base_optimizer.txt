# Gradient Based Optimization - practical 2
import tensorflow as tf
import matplotlib.pyplot as plt

def loss_function(x):
    return (x-3)**2

x = tf.Variable(initial_value = 5.0, trainable = True, dtype = tf.float32)
learning_rate = 0.1
steps = []
loss_values = []
for step in range(20):
    with tf.GradientTape() as tape:
        loss = loss_function(x)

    gradients = tape.gradient(loss, [x])

    x.assign_sub(learning_rate*gradients[0])

    steps.append(step)
    loss_values.append(loss.numpy())

    print(f"Step {step+1}: x = {x.numpy():.4f}, Loss = {loss.numpy():.4f}")

plt.plot(steps, loss_values, marker='o')
plt.title('Gradient-Based Optimization: :Loss Reduction')
plt.xlabel('Steps')
plt.ylabel('Loss')
plt.grid(True)
plt.show()

# Using Tensorflow Optimizers
x = tf.Variable(initial_value = 5.0, trainable = True, dtype = tf.float32)

optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)
adam_steps = []
adam_loss_values = []

for step in range(20):
    with tf.GradientTape() as tape:
        loss = loss_function(x)

    gradients = tape.gradient(loss, [x])

    optimizer.apply_gradients(zip(gradients, [x]))

    adam_steps.append(step)
    adam_loss_values.append(loss.numpy())

    print(f"Step {step+1} (Adam): x = {x.numpy():.4f}, Loss = {loss.numpy():.4f}")

plt.plot(adam_steps, adam_loss_values, marker='o', color='red')
plt.title('Adam Optimization: Loss Reduction')
plt.xlabel('Steps')
plt.ylabel('Loss')
plt.grid('True')
plt.show()
